{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6x1ypzczQCwy"
   },
   "source": [
    "# Simple TFX Pipeline for Vertex Pipelines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_VuwrlnvQJ5k"
   },
   "source": [
    "This notebook-based tutorial will create a simple TFX pipeline and run it using\n",
    "Google Cloud Vertex Pipelines.  This notebook is based on the TFX pipeline\n",
    "built in\n",
    "[Simple TFX Pipeline Tutorial](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "\n",
    "Google Cloud Vertex Pipelines helps you to automate, monitor, and govern\n",
    "your ML systems by orchestrating your ML workflow in a serverless manner. You\n",
    "can define your ML pipelines using Python with TFX, and then execute your\n",
    "pipelines on Google Cloud. See\n",
    "[Vertex Pipelines introduction](https://cloud.google.com/vertex-ai/docs/pipelines/introduction)\n",
    "to learn more about Vertex Pipelines."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fwZ0aXisoBFW"
   },
   "source": [
    "## Setup\n",
    "### Install python packages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WC9W_S-bONgl"
   },
   "source": [
    "We will install required Python packages including TFX and KFP to author ML\n",
    "pipelines and submit jobs to Vertex Pipelines."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "iyQtljP-qPHY",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in /opt/conda/lib/python3.10/site-packages (25.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping tensorflow as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-tensorboard as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-io as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0m\u001b[33mWARNING: Skipping tensorflow-cloud as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting tensorflow==2.15.1\n",
      "  Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (2.3.1)\n",
      "Collecting astunparse>=1.6.0 (from tensorflow==2.15.1)\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl.metadata (4.4 kB)\n",
      "Collecting flatbuffers>=23.5.26 (from tensorflow==2.15.1)\n",
      "  Downloading flatbuffers-25.9.23-py2.py3-none-any.whl.metadata (875 bytes)\n",
      "Collecting gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 (from tensorflow==2.15.1)\n",
      "  Downloading gast-0.6.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting google-pasta>=0.1.1 (from tensorflow==2.15.1)\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl.metadata (814 bytes)\n",
      "Collecting h5py>=2.9.0 (from tensorflow==2.15.1)\n",
      "  Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n",
      "Collecting libclang>=13.0.0 (from tensorflow==2.15.1)\n",
      "  Downloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl.metadata (5.2 kB)\n",
      "Collecting ml-dtypes~=0.3.1 (from tensorflow==2.15.1)\n",
      "  Downloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.26.4)\n",
      "Collecting opt-einsum>=2.3.2 (from tensorflow==2.15.1)\n",
      "  Downloading opt_einsum-3.4.0-py3-none-any.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (25.0)\n",
      "Collecting protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 (from tensorflow==2.15.1)\n",
      "  Downloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl.metadata (541 bytes)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (80.9.0)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.17.0)\n",
      "Collecting termcolor>=1.1.0 (from tensorflow==2.15.1)\n",
      "  Downloading termcolor-3.1.0-py3-none-any.whl.metadata (6.4 kB)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (4.15.0)\n",
      "Collecting wrapt<1.15,>=1.11.0 (from tensorflow==2.15.1)\n",
      "  Downloading wrapt-1.14.2-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl.metadata (6.5 kB)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.15.1)\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (14 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.10/site-packages (from tensorflow==2.15.1) (1.75.0)\n",
      "Collecting tensorboard<2.16,>=2.15 (from tensorflow==2.15.1)\n",
      "  Downloading tensorboard-2.15.2-py3-none-any.whl.metadata (1.7 kB)\n",
      "Collecting tensorflow-estimator<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
      "  Downloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting keras<2.16,>=2.15.0 (from tensorflow==2.15.1)\n",
      "  Downloading keras-2.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.40.3)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (1.2.2)\n",
      "Collecting markdown>=2.6.8 (from tensorboard<2.16,>=2.15->tensorflow==2.15.1)\n",
      "  Downloading markdown-3.9-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.32.5)\n",
      "Collecting tensorboard-data-server<0.8.0,>=0.7.0 (from tensorboard<2.16,>=2.15->tensorflow==2.15.1)\n",
      "  Downloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl.metadata (1.1 kB)\n",
      "Collecting werkzeug>=1.0.1 (from tensorboard<2.16,>=2.15->tensorflow==2.15.1)\n",
      "  Downloading werkzeug-3.1.3-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (4.9.1)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.0.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.4.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2.21.0->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (2025.8.3)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.6.3->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (0.6.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.10/site-packages (from astunparse>=1.6.0->tensorflow==2.15.1) (0.45.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<2,>=0.5->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.3.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /opt/conda/lib/python3.10/site-packages (from werkzeug>=1.0.1->tensorboard<2.16,>=2.15->tensorflow==2.15.1) (3.0.2)\n",
      "Downloading tensorflow-2.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (475.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m475.2/475.2 MB\u001b[0m \u001b[31m41.2 MB/s\u001b[0m  \u001b[33m0:00:08\u001b[0mm0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading keras-2.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_dtypes-0.3.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m78.5 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading protobuf-4.25.8-cp37-abi3-manylinux2014_x86_64.whl (294 kB)\n",
      "Downloading tensorboard-2.15.2-py3-none-any.whl (5.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m75.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorboard_data_server-0.7.2-py3-none-manylinux_2_31_x86_64.whl (6.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m81.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_estimator-2.15.0-py2.py3-none-any.whl (441 kB)\n",
      "Downloading wrapt-1.14.2-cp310-cp310-manylinux1_x86_64.manylinux_2_28_x86_64.manylinux_2_5_x86_64.whl (76 kB)\n",
      "Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Downloading flatbuffers-25.9.23-py2.py3-none-any.whl (30 kB)\n",
      "Downloading gast-0.6.0-py3-none-any.whl (21 kB)\n",
      "Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "Downloading h5py-3.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m86.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading libclang-18.1.1-py2.py3-none-manylinux2010_x86_64.whl (24.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.5/24.5 MB\u001b[0m \u001b[31m89.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading markdown-3.9-py3-none-any.whl (107 kB)\n",
      "Downloading opt_einsum-3.4.0-py3-none-any.whl (71 kB)\n",
      "Downloading tensorflow_io_gcs_filesystem-0.37.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m77.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading termcolor-3.1.0-py3-none-any.whl (7.7 kB)\n",
      "Downloading werkzeug-3.1.3-py3-none-any.whl (224 kB)\n",
      "Installing collected packages: libclang, flatbuffers, wrapt, werkzeug, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, protobuf, opt-einsum, ml-dtypes, markdown, keras, h5py, google-pasta, gast, astunparse, tensorboard, tensorflow\n",
      "\u001b[2K  Attempting uninstall: wrapt━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/19\u001b[0m [libclang]\n",
      "\u001b[2K    Found existing installation: wrapt 1.17.3[0m \u001b[32m 0/19\u001b[0m [libclang]\n",
      "\u001b[2K    Uninstalling wrapt-1.17.3:━━━━━━━━━━━━━━\u001b[0m \u001b[32m 0/19\u001b[0m [libclang]\n",
      "\u001b[2K      Successfully uninstalled wrapt-1.17.3━\u001b[0m \u001b[32m 0/19\u001b[0m [libclang]\n",
      "\u001b[2K  Attempting uninstall: protobuf\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/19\u001b[0m [tensorboard-data-server]stem]\n",
      "\u001b[2K    Found existing installation: protobuf 6.31.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/19\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K    Uninstalling protobuf-6.31.1:[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/19\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K      Successfully uninstalled protobuf-6.31.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 7/19\u001b[0m [tensorboard-data-server]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/19\u001b[0m [protobuf]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/google/~rotobuf'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/19\u001b[0m [tensorflow]9\u001b[0m [tensorflow]]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "grpcio-status 1.75.0 requires protobuf<7.0.0,>=6.31.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "kfp 2.14.3 requires protobuf<7.0,==6.31.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "kfp-pipeline-spec 2.14.0 requires protobuf<7.0,==6.31.1, but you have protobuf 4.25.8 which is incompatible.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 4.25.8 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed astunparse-1.6.3 flatbuffers-25.9.23 gast-0.6.0 google-pasta-0.2.0 h5py-3.14.0 keras-2.15.0 libclang-18.1.1 markdown-3.9 ml-dtypes-0.3.2 opt-einsum-3.4.0 protobuf-4.25.8 tensorboard-2.15.2 tensorboard-data-server-0.7.2 tensorflow-2.15.1 tensorflow-estimator-2.15.0 tensorflow-io-gcs-filesystem-0.37.1 termcolor-3.1.0 werkzeug-3.1.3 wrapt-1.14.2\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "\u001b[33mWARNING: Skipping tfx as it is not installed.\u001b[0m\u001b[33m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n",
      "Collecting tfx==1.15.0 (from tfx[kfp]==1.15.0)\n",
      "  Downloading tfx-1.15.0-py3-none-any.whl.metadata (23 kB)\n",
      "Collecting ml-pipelines-sdk==1.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ml_pipelines_sdk-1.15.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting absl-py<2.0.0,>=0.9 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading absl_py-1.4.0-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting ml-metadata<1.16.0,>=1.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.0 kB)\n",
      "Requirement already satisfied: packaging>=22 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (25.0)\n",
      "Collecting portpicker<2,>=1.3.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading portpicker-1.6.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: protobuf<5,>=3.20.3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (4.25.8)\n",
      "Collecting docker<5,>=4.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading docker-4.4.4-py2.py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting google-apitools<1,>=0.5 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_apitools-0.5.35-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting google-api-python-client<2,>=1.8 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: jinja2<4,>=2.7.3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (3.1.6)\n",
      "Requirement already satisfied: typing-extensions<5,>=3.10.0.2 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (4.15.0)\n",
      "Collecting apache-beam<3,>=2.47 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading apache_beam-2.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
      "Collecting attrs<24,>=19.3.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading attrs-23.2.0-py3-none-any.whl.metadata (9.5 kB)\n",
      "Requirement already satisfied: click<9,>=7 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (8.1.8)\n",
      "Requirement already satisfied: google-api-core<3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-aiplatform<2,>=1.6.2 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.113.0)\n",
      "Requirement already satisfied: google-cloud-bigquery<4,>=3 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (3.37.0)\n",
      "Requirement already satisfied: grpcio<2,>=1.28.1 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.75.0)\n",
      "Collecting keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading keras_tuner-1.4.7-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting kubernetes<13,>=10.0.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading kubernetes-12.0.1-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: numpy<2,>=1.16 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (1.26.4)\n",
      "Collecting pyarrow<11,>=10 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.0 kB)\n",
      "Collecting scipy<1.13 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "Requirement already satisfied: pyyaml<7,>=6 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (6.0.2)\n",
      "Requirement already satisfied: tensorflow<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.1)\n",
      "Collecting tensorflow-hub<0.16,>=0.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_hub-0.15.0-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting tensorflow-data-validation<1.16.0,>=1.15.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
      "Collecting tensorflow-model-analysis<0.47.0,>=0.46.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl.metadata (20 kB)\n",
      "Collecting tensorflow-serving-api<2.16,>=2.15 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting tensorflow-transform<1.16.0,>=1.15.0 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_transform-1.15.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting tfx-bsl<1.16.0,>=1.15.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting kfp<2,>=1.8.14 (from tfx[kfp]==1.15.0)\n",
      "  Downloading kfp-1.8.23-py3-none-any.whl.metadata (6.1 kB)\n",
      "Collecting kfp-pipeline-spec<0.2,>=0.1.10 (from tfx[kfp]==1.15.0)\n",
      "  Downloading kfp_pipeline_spec-0.1.16-py3-none-any.whl.metadata (323 bytes)\n",
      "Collecting crcmod<2.0,>=1.7 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading crcmod-1.7.tar.gz (89 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting orjson<4,>=3.9.7 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading orjson-3.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (41 kB)\n",
      "Collecting dill<0.3.2,>=0.3.1.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading dill-0.3.1.1.tar.gz (151 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting fastavro<2,>=0.23.6 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading fastavro-1.12.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (5.7 kB)\n",
      "Collecting fasteners<1.0,>=0.3 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading fasteners-0.20-py3-none-any.whl.metadata (4.8 kB)\n",
      "Collecting grpcio<2,>=1.28.1 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.3 kB)\n",
      "Collecting hdfs<3.0.0,>=2.1.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading hdfs-2.7.3.tar.gz (43 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting httplib2<0.23.0,>=0.8 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading httplib2-0.22.0-py3-none-any.whl.metadata (2.6 kB)\n",
      "Requirement already satisfied: jsonschema<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (4.25.1)\n",
      "Collecting jsonpickle<4.0.0,>=3.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading jsonpickle-3.4.2-py3-none-any.whl.metadata (8.1 kB)\n",
      "Collecting objsize<0.8.0,>=0.6.1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading objsize-0.7.1-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting pymongo<5.0.0,>=3.8.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pymongo-4.15.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (22 kB)\n",
      "Requirement already satisfied: proto-plus<2,>=1.7.1 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.26.1)\n",
      "Collecting pydot<2,>=1.2.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pydot-1.4.2-py2.py3-none-any.whl.metadata (8.0 kB)\n",
      "Requirement already satisfied: python-dateutil<3,>=2.8.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2018.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2025.2)\n",
      "Collecting redis<6,>=5.0.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading redis-5.3.1-py3-none-any.whl.metadata (9.2 kB)\n",
      "Collecting regex>=2020.6.8 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl.metadata (40 kB)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.32.4 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.32.5)\n",
      "Collecting sortedcontainers>=2.4.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl.metadata (10 kB)\n",
      "Requirement already satisfied: zstandard<1,>=0.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.25.0)\n",
      "Collecting beartype<0.22.0,>=0.21.0 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading beartype-0.21.0-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting pyarrow-hotfix<1 (from apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pyarrow_hotfix-0.7-py3-none-any.whl.metadata (3.6 kB)\n",
      "Requirement already satisfied: cachetools<7,>=3.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (5.5.2)\n",
      "Collecting google-apitools<1,>=0.5 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google-apitools-0.5.31.tar.gz (173 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: google-auth<3,>=1.18.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.40.3)\n",
      "Requirement already satisfied: google-auth-httplib2<0.3.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: google-cloud-datastore<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.21.0)\n",
      "Collecting google-cloud-pubsub<3,>=2.1.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_pubsub-2.31.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-pubsublite<2,>=1.2.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Requirement already satisfied: google-cloud-storage<3,>=2.18.2 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.19.0)\n",
      "Requirement already satisfied: google-cloud-bigquery-storage<3,>=2.6.3 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.33.1)\n",
      "Requirement already satisfied: google-cloud-core<3,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.4.3)\n",
      "Collecting google-cloud-bigtable<3,>=2.19.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_bigtable-2.32.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting google-cloud-spanner<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_spanner-3.58.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting google-cloud-dlp<4,>=3.0.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_dlp-3.32.0-py3-none-any.whl.metadata (9.7 kB)\n",
      "Requirement already satisfied: google-cloud-language<3,>=2.0 in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.17.2)\n",
      "Collecting google-cloud-videointelligence<3,>=2.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_videointelligence-2.16.2-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting google-cloud-vision<4,>=2 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_vision-3.10.2-py3-none-any.whl.metadata (9.6 kB)\n",
      "Collecting google-cloud-recommendations-ai<0.11.0,>=0.1.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_recommendations_ai-0.10.18-py3-none-any.whl.metadata (9.7 kB)\n",
      "Collecting cloud-sql-python-connector<2.0.0,>=1.18.2 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading cloud_sql_python_connector-1.18.4-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting python-tds>=1.16.1 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading python_tds-1.17.1-py3-none-any.whl.metadata (804 bytes)\n",
      "Collecting pg8000>=1.31.1 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pg8000-1.31.5-py3-none-any.whl.metadata (88 kB)\n",
      "Collecting PyMySQL>=1.1.0 (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pymysql-1.1.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Requirement already satisfied: keyrings.google-artifactregistry-auth in /opt/conda/lib/python3.10/site-packages (from apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.1.2)\n",
      "Requirement already satisfied: aiofiles in /opt/conda/lib/python3.10/site-packages (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (22.1.0)\n",
      "Requirement already satisfied: aiohttp in /opt/conda/lib/python3.10/site-packages (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.12.15)\n",
      "Requirement already satisfied: cryptography>=42.0.0 in /opt/conda/lib/python3.10/site-packages (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (45.0.7)\n",
      "Collecting dnspython>=2.0.0 (from cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading dnspython-2.8.0-py3-none-any.whl.metadata (5.7 kB)\n",
      "Requirement already satisfied: six>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from docker<5,>=4.1->tfx==1.15.0->tfx[kfp]==1.15.0) (1.17.0)\n",
      "Requirement already satisfied: websocket-client>=0.32.0 in /opt/conda/lib/python3.10/site-packages (from docker<5,>=4.1->tfx==1.15.0->tfx[kfp]==1.15.0) (1.8.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core<3->tfx==1.15.0->tfx[kfp]==1.15.0) (1.70.0)\n",
      "Collecting uritemplate<4dev,>=3.0.0 (from google-api-python-client<2,>=1.8->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading uritemplate-3.0.1-py2.py3-none-any.whl.metadata (4.6 kB)\n",
      "Requirement already satisfied: oauth2client>=1.4.12 in /opt/conda/lib/python3.10/site-packages (from google-apitools<1,>=0.5->tfx==1.15.0->tfx[kfp]==1.15.0) (4.1.3)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.10/site-packages (from google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (4.9.1)\n",
      "Requirement already satisfied: google-cloud-resource-manager<3.0.0,>=1.3.3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.14.2)\n",
      "Requirement already satisfied: shapely<3.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (2.1.1)\n",
      "Requirement already satisfied: google-genai<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.37.0)\n",
      "Requirement already satisfied: pydantic<3 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (2.11.9)\n",
      "Requirement already satisfied: docstring_parser<1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (0.17.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in /opt/conda/lib/python3.10/site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.75.0)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigquery<4,>=3->tfx==1.15.0->tfx[kfp]==1.15.0) (2.7.2)\n",
      "Requirement already satisfied: grpc-google-iam-v1<1.0.0,>=0.12.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.14.2)\n",
      "Requirement already satisfied: google-crc32c<2.0.0dev,>=1.5.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-bigtable<3,>=2.19.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.7.1)\n",
      "Requirement already satisfied: opentelemetry-api>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.37.0)\n",
      "Requirement already satisfied: opentelemetry-sdk>=1.27.0 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.37.0)\n",
      "Requirement already satisfied: overrides<8.0.0,>=6.0.1 in /opt/conda/lib/python3.10/site-packages (from google-cloud-pubsublite<2,>=1.2.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (7.7.0)\n",
      "Requirement already satisfied: sqlparse>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.5.3)\n",
      "Collecting grpc-interceptor>=0.15.4 (from google-cloud-spanner<4,>=3.0.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading grpc_interceptor-0.15.4-py3-none-any.whl.metadata (8.4 kB)\n",
      "Requirement already satisfied: anyio<5.0.0,>=4.8.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (4.10.0)\n",
      "Requirement already satisfied: httpx<1.0.0,>=0.28.1 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (0.28.1)\n",
      "Requirement already satisfied: tenacity<9.2.0,>=8.2.3 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (9.1.2)\n",
      "Requirement already satisfied: websockets<15.1.0,>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (15.0.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.0)\n",
      "Requirement already satisfied: idna>=2.8 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (3.10)\n",
      "Requirement already satisfied: sniffio>=1.1 in /opt/conda/lib/python3.10/site-packages (from anyio<5.0.0,>=4.8.0->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.1)\n",
      "INFO: pip is looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading grpcio_status-1.75.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.75.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.74.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.73.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: pip is still looking at multiple versions of grpcio-status to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading grpcio_status-1.72.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.72.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.71.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.71.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.70.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.69.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.68.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.67.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.66.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.5-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.4-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.65.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.3-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.64.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc2-py3-none-any.whl.metadata (1.1 kB)\n",
      "  Downloading grpcio_status-1.63.0rc1-py3-none-any.whl.metadata (1.1 kB)\n",
      "Collecting docopt (from hdfs<3.0.0,>=2.1.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading docopt-0.6.2.tar.gz (25 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /opt/conda/lib/python3.10/site-packages (from httplib2<0.23.0,>=0.8->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.2.4)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (2025.8.3)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (1.0.9)\n",
      "Requirement already satisfied: h11>=0.16 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<1.0.0,>=0.28.1->google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0) (0.16.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2<4,>=2.7.3->tfx==1.15.0->tfx[kfp]==1.15.0) (3.0.2)\n",
      "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2025.9.1)\n",
      "Requirement already satisfied: referencing>=0.28.4 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.36.2)\n",
      "Requirement already satisfied: rpds-py>=0.7.1 in /opt/conda/lib/python3.10/site-packages (from jsonschema<5.0.0,>=4.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.27.1)\n",
      "Requirement already satisfied: keras in /opt/conda/lib/python3.10/site-packages (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.0)\n",
      "Collecting kt-legacy (from keras-tuner!=1.4.0,!=1.4.1,<2,>=1.0.4->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading kt_legacy-1.0.5-py3-none-any.whl.metadata (221 bytes)\n",
      "Requirement already satisfied: requests-toolbelt<2,>=0.8.0 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (1.0.0)\n",
      "Collecting cloudpickle<3,>=2.0.0 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading cloudpickle-2.2.1-py3-none-any.whl.metadata (6.9 kB)\n",
      "Collecting kfp-server-api<2.0.0,>=1.1.2 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading kfp-server-api-1.8.5.tar.gz (58 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: tabulate<1,>=0.8.6 in /opt/conda/lib/python3.10/site-packages (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (0.9.0)\n",
      "Collecting Deprecated<2,>=1.2.7 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading Deprecated-1.2.18-py2.py3-none-any.whl.metadata (5.7 kB)\n",
      "Collecting strip-hints<1,>=0.1.8 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading strip_hints-0.1.13-py3-none-any.whl.metadata (11 kB)\n",
      "INFO: pip is looking at multiple versions of kfp to determine which version is compatible with other requirements. This could take a while.\n",
      "Collecting kfp<2,>=1.8.14 (from tfx[kfp]==1.15.0)\n",
      "  Downloading kfp-1.8.22.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting requests-toolbelt<1,>=0.8.0 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl.metadata (14 kB)\n",
      "Collecting fire<1,>=0.3.1 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading fire-0.7.1-py3-none-any.whl.metadata (5.8 kB)\n",
      "Collecting kfp<2,>=1.8.14 (from tfx[kfp]==1.15.0)\n",
      "  Downloading kfp-1.8.21.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading kfp-1.8.20.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading kfp-1.8.19.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading kfp-1.8.18.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading kfp-1.8.17.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading kfp-1.8.16.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hINFO: pip is still looking at multiple versions of kfp to determine which version is compatible with other requirements. This could take a while.\n",
      "  Downloading kfp-1.8.15.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Downloading kfp-1.8.14.tar.gz (304 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting grpcio-status<2.0.0,>=1.33.2 (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,<3.0.0,>=1.34.1->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading grpcio_status-1.62.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "INFO: This is taking longer than usual. You might need to provide the dependency resolver with stricter constraints to reduce runtime. See https://pip.pypa.io/warnings/backtracking for guidance. If you want to abort this run, press Ctrl + C.\n",
      "  Downloading grpcio_status-1.62.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.62.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.61.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.60.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.5-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.59.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.58.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.57.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading grpcio_status-1.57.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.56.0rc2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.55.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.55.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.54.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.53.0rc2-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.52.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.3-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.51.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.50.0-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.50.0rc1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.49.1-py3-none-any.whl.metadata (1.3 kB)\n",
      "  Downloading grpcio_status-1.49.0rc3-py3-none-any.whl.metadata (1.2 kB)\n",
      "  Downloading grpcio_status-1.49.0rc1-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting protobuf<5,>=3.20.3 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl.metadata (679 bytes)\n",
      "Collecting urllib3<2 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading urllib3-1.26.20-py2.py3-none-any.whl.metadata (50 kB)\n",
      "Collecting google-genai<2.0.0,>=1.0.0 (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_genai-1.40.0-py3-none-any.whl.metadata (45 kB)\n",
      "  Downloading google_genai-1.39.1-py3-none-any.whl.metadata (45 kB)\n",
      "  Downloading google_genai-1.39.0-py3-none-any.whl.metadata (45 kB)\n",
      "  Downloading google_genai-1.38.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.37.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.36.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.35.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.34.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.33.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.32.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.31.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.30.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.29.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.28.0-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting tenacity<9.0.0,>=8.2.3 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting google-genai<2.0.0,>=1.0.0 (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_genai-1.27.0-py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_genai-1.26.0-py3-none-any.whl.metadata (42 kB)\n",
      "  Downloading google_genai-1.25.0-py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading google_genai-1.24.0-py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading google_genai-1.23.0-py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_genai-1.22.0-py3-none-any.whl.metadata (37 kB)\n",
      "  Downloading google_genai-1.21.1-py3-none-any.whl.metadata (37 kB)\n",
      "  Downloading google_genai-1.21.0-py3-none-any.whl.metadata (37 kB)\n",
      "  Downloading google_genai-1.20.0-py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_genai-1.19.0-py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_genai-1.18.0-py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_genai-1.17.0-py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_genai-1.16.1-py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_genai-1.15.0-py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_genai-1.14.0-py3-none-any.whl.metadata (33 kB)\n",
      "  Downloading google_genai-1.13.0-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading google_genai-1.12.1-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading google_genai-1.11.0-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading google_genai-1.10.0-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading google_genai-1.9.0-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading google_genai-1.8.0-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading google_genai-1.7.0-py3-none-any.whl.metadata (32 kB)\n",
      "  Downloading google_genai-1.5.0-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting websockets<15.0dev,>=13.0 (from google-genai<2.0.0,>=1.0.0->google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading websockets-14.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
      "Collecting google-genai<2.0.0,>=1.0.0 (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_genai-1.4.0-py3-none-any.whl.metadata (29 kB)\n",
      "  Downloading google_genai-1.3.0-py3-none-any.whl.metadata (28 kB)\n",
      "  Downloading google_genai-1.2.0-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading google_genai-1.1.0-py3-none-any.whl.metadata (26 kB)\n",
      "  Downloading google_genai-1.0.0-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting google-cloud-aiplatform<2,>=1.6.2 (from tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading google_cloud_aiplatform-1.118.0-py2.py3-none-any.whl.metadata (43 kB)\n",
      "  Downloading google_cloud_aiplatform-1.117.0-py2.py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading google_cloud_aiplatform-1.116.0-py2.py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading google_cloud_aiplatform-1.115.0-py2.py3-none-any.whl.metadata (41 kB)\n",
      "  Downloading google_cloud_aiplatform-1.114.0-py2.py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading google_cloud_aiplatform-1.113.0-py2.py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading google_cloud_aiplatform-1.112.0-py2.py3-none-any.whl.metadata (40 kB)\n",
      "  Downloading google_cloud_aiplatform-1.111.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.110.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.109.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.108.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.107.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.106.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.105.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.104.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.103.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.102.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.101.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.100.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.99.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.98.0-py2.py3-none-any.whl.metadata (38 kB)\n",
      "  Downloading google_cloud_aiplatform-1.97.0-py2.py3-none-any.whl.metadata (36 kB)\n",
      "  Downloading google_cloud_aiplatform-1.96.0-py2.py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_cloud_aiplatform-1.95.1-py2.py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_cloud_aiplatform-1.95.0-py2.py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_cloud_aiplatform-1.94.0-py2.py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_cloud_aiplatform-1.93.1-py2.py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_cloud_aiplatform-1.93.0-py2.py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_cloud_aiplatform-1.92.0-py2.py3-none-any.whl.metadata (35 kB)\n",
      "  Downloading google_cloud_aiplatform-1.91.0-py2.py3-none-any.whl.metadata (35 kB)\n",
      "Collecting pydantic<3 (from google-cloud-aiplatform<2,>=1.6.2->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pydantic-1.10.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (154 kB)\n",
      "Collecting typer<1.0,>=0.3.2 (from kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading typer-0.19.2-py3-none-any.whl.metadata (16 kB)\n",
      "Requirement already satisfied: wrapt<2,>=1.10 in /opt/conda/lib/python3.10/site-packages (from Deprecated<2,>=1.2.7->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (1.14.2)\n",
      "Requirement already satisfied: termcolor in /opt/conda/lib/python3.10/site-packages (from fire<1,>=0.3.1->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (3.1.0)\n",
      "Requirement already satisfied: setuptools>=21.0.0 in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx==1.15.0->tfx[kfp]==1.15.0) (80.9.0)\n",
      "Requirement already satisfied: requests-oauthlib in /opt/conda/lib/python3.10/site-packages (from kubernetes<13,>=10.0.1->tfx==1.15.0->tfx[kfp]==1.15.0) (2.0.0)\n",
      "Requirement already satisfied: psutil in /opt/conda/lib/python3.10/site-packages (from portpicker<2,>=1.3.1->tfx==1.15.0->tfx[kfp]==1.15.0) (5.9.3)\n",
      "Collecting PyJWT>=2.9.0 (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading PyJWT-2.10.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: async-timeout>=4.0.3 in /opt/conda/lib/python3.10/site-packages (from redis<6,>=5.0.0->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (5.0.1)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.32.4->apache-beam<3,>=2.47->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.4.2)\n",
      "Requirement already satisfied: pyasn1>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from rsa<5,>=3.1.4->google-auth<3,>=1.18.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.6.1)\n",
      "Requirement already satisfied: wheel in /opt/conda/lib/python3.10/site-packages (from strip-hints<1,>=0.1.8->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (0.45.1)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (25.9.23)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.14.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.4.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.37.1)\n",
      "Requirement already satisfied: tensorboard<2.16,>=2.15 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.2)\n",
      "Requirement already satisfied: tensorflow-estimator<2.16,>=2.15.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.15.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<2,>=0.5 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.2.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.9)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.10/site-packages (from tensorboard<2.16,>=2.15->tensorflow<2.16,>=2.15.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.1.3)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0) (1.5.2)\n",
      "Collecting pandas<2,>=1.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting pyfarmhash<0.4,>=0.2.2 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pyfarmhash-0.3.2.tar.gz (99 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting tensorflow-metadata<1.16,>=1.15.0 (from tensorflow-data-validation<1.16.0,>=1.15.1->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading tensorflow_metadata-1.15.0-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting ipython<8,>=7 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ipython-7.34.0-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting ipywidgets<8,>=7 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading ipywidgets-7.8.5-py2.py3-none-any.whl.metadata (1.9 kB)\n",
      "Requirement already satisfied: pillow>=9.4.0 in /opt/conda/lib/python3.10/site-packages (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (11.3.0)\n",
      "Collecting rouge-score<2,>=0.1.2 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading rouge_score-0.1.2.tar.gz (17 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting sacrebleu<4,>=2.3 (from tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading sacrebleu-2.5.1-py3-none-any.whl.metadata (51 kB)\n",
      "Requirement already satisfied: jedi>=0.16 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.19.2)\n",
      "Requirement already satisfied: decorator in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.2.1)\n",
      "Collecting pickleshare (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: traitlets>=4.2 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.14.3)\n",
      "Requirement already satisfied: prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.0.52)\n",
      "Requirement already satisfied: pygments in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.19.2)\n",
      "Collecting backcall (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading backcall-0.2.0-py2.py3-none-any.whl.metadata (2.0 kB)\n",
      "Requirement already satisfied: matplotlib-inline in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.1.7)\n",
      "Requirement already satisfied: pexpect>4.3 in /opt/conda/lib/python3.10/site-packages (from ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.9.0)\n",
      "Requirement already satisfied: comm>=0.1.3 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.3)\n",
      "Requirement already satisfied: ipython-genutils~=0.2.0 in /opt/conda/lib/python3.10/site-packages (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.0)\n",
      "Collecting widgetsnbextension~=3.6.10 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading widgetsnbextension-3.6.10-py2.py3-none-any.whl.metadata (1.3 kB)\n",
      "Collecting jupyterlab-widgets<3,>=1.0.0 (from ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading jupyterlab_widgets-1.1.11-py3-none-any.whl.metadata (3.7 kB)\n",
      "Requirement already satisfied: wcwidth in /opt/conda/lib/python3.10/site-packages (from prompt-toolkit!=3.0.0,!=3.0.1,<3.1.0,>=2.0.0->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.13)\n",
      "Collecting nltk (from rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading nltk-3.9.2-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting portalocker (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading portalocker-3.2.0-py3-none-any.whl.metadata (8.7 kB)\n",
      "Requirement already satisfied: colorama in /opt/conda/lib/python3.10/site-packages (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.4.6)\n",
      "Collecting lxml (from sacrebleu<4,>=2.3->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl.metadata (3.6 kB)\n",
      "Collecting shellingham>=1.3.0 (from typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0)\n",
      "  Downloading shellingham-1.5.4-py2.py3-none-any.whl.metadata (3.5 kB)\n",
      "Requirement already satisfied: rich>=10.11.0 in /opt/conda/lib/python3.10/site-packages (from typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (13.9.4)\n",
      "Requirement already satisfied: notebook>=4.4.1 in /opt/conda/lib/python3.10/site-packages (from widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.5.7)\n",
      "Requirement already satisfied: cffi>=1.14 in /opt/conda/lib/python3.10/site-packages (from cryptography>=42.0.0->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.17.1)\n",
      "Requirement already satisfied: pycparser in /opt/conda/lib/python3.10/site-packages (from cffi>=1.14->cryptography>=42.0.0->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.22)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.4 in /opt/conda/lib/python3.10/site-packages (from jedi>=0.16->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.8.5)\n",
      "Requirement already satisfied: tornado>=6.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.5.2)\n",
      "Requirement already satisfied: pyzmq>=17 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (27.1.0)\n",
      "Requirement already satisfied: argon2-cffi in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (25.1.0)\n",
      "Requirement already satisfied: jupyter-core>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.8.1)\n",
      "Requirement already satisfied: jupyter-client<8,>=5.3.4 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (7.4.9)\n",
      "Requirement already satisfied: nbformat in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (5.10.4)\n",
      "Requirement already satisfied: nbconvert>=5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (7.16.6)\n",
      "Requirement already satisfied: nest-asyncio>=1.5 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.6.0)\n",
      "Requirement already satisfied: ipykernel in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.29.5)\n",
      "Requirement already satisfied: Send2Trash>=1.8.0 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.8.3)\n",
      "Requirement already satisfied: terminado>=0.8.3 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.18.1)\n",
      "Requirement already satisfied: prometheus-client in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.22.1)\n",
      "Requirement already satisfied: nbclassic>=0.4.7 in /opt/conda/lib/python3.10/site-packages (from notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.2)\n",
      "Requirement already satisfied: entrypoints in /opt/conda/lib/python3.10/site-packages (from jupyter-client<8,>=5.3.4->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.4)\n",
      "Requirement already satisfied: platformdirs>=2.5 in /opt/conda/lib/python3.10/site-packages (from jupyter-core>=4.6.1->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.3.8)\n",
      "Requirement already satisfied: notebook-shim>=0.2.3 in /opt/conda/lib/python3.10/site-packages (from nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.2.4)\n",
      "Requirement already satisfied: beautifulsoup4 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.13.5)\n",
      "Requirement already satisfied: bleach!=5.0.0 in /opt/conda/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (6.2.0)\n",
      "Requirement already satisfied: defusedxml in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.7.1)\n",
      "Requirement already satisfied: jupyterlab-pygments in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.3.0)\n",
      "Requirement already satisfied: mistune<4,>=2.0.3 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.1.4)\n",
      "Requirement already satisfied: nbclient>=0.5.0 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.10.2)\n",
      "Requirement already satisfied: pandocfilters>=1.4.1 in /opt/conda/lib/python3.10/site-packages (from nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.5.1)\n",
      "Requirement already satisfied: webencodings in /opt/conda/lib/python3.10/site-packages (from bleach!=5.0.0->bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.5.1)\n",
      "Requirement already satisfied: tinycss2<1.5,>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from bleach[css]!=5.0.0->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.4.0)\n",
      "Requirement already satisfied: fastjsonschema>=2.15 in /opt/conda/lib/python3.10/site-packages (from nbformat->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.21.2)\n",
      "Requirement already satisfied: jupyter-server<3,>=1.8 in /opt/conda/lib/python3.10/site-packages (from notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.17.0)\n",
      "Requirement already satisfied: jupyter-events>=0.11.0 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.12.0)\n",
      "Requirement already satisfied: jupyter-server-terminals>=0.4.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.5.3)\n",
      "Requirement already satisfied: argon2-cffi-bindings in /opt/conda/lib/python3.10/site-packages (from argon2-cffi->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (25.1.0)\n",
      "Requirement already satisfied: python-json-logger>=2.0.4 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.3.0)\n",
      "Requirement already satisfied: rfc3339-validator in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.1.4)\n",
      "Requirement already satisfied: rfc3986-validator>=0.1.1 in /opt/conda/lib/python3.10/site-packages (from jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.1.1)\n",
      "Requirement already satisfied: fqdn in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.5.1)\n",
      "Requirement already satisfied: isoduration in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (20.11.0)\n",
      "Requirement already satisfied: jsonpointer>1.13 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (3.0.0)\n",
      "Requirement already satisfied: rfc3987-syntax>=1.1.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.1.0)\n",
      "Requirement already satisfied: uri-template in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.0)\n",
      "Requirement already satisfied: webcolors>=24.6.0 in /opt/conda/lib/python3.10/site-packages (from jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (24.11.1)\n",
      "Requirement already satisfied: importlib-metadata<8.8.0,>=6.0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (8.7.0)\n",
      "Requirement already satisfied: zipp>=3.20 in /opt/conda/lib/python3.10/site-packages (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.23.0)\n",
      "Requirement already satisfied: opentelemetry-semantic-conventions==0.58b0 in /opt/conda/lib/python3.10/site-packages (from opentelemetry-sdk>=1.27.0->google-cloud-pubsub<3,>=2.1.0->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.58b0)\n",
      "Requirement already satisfied: ptyprocess>=0.5 in /opt/conda/lib/python3.10/site-packages (from pexpect>4.3->ipython<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (0.7.0)\n",
      "Collecting scramp>=1.4.5 (from pg8000>=1.31.1->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading scramp-1.4.6-py3-none-any.whl.metadata (19 kB)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from requests-oauthlib->kubernetes<13,>=10.0.1->tfx==1.15.0->tfx[kfp]==1.15.0) (3.3.1)\n",
      "Requirement already satisfied: lark>=1.2.2 in /opt/conda/lib/python3.10/site-packages (from rfc3987-syntax>=1.1.0->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.2.2)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /opt/conda/lib/python3.10/site-packages (from rich>=10.11.0->typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (4.0.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /opt/conda/lib/python3.10/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.3.2->kfp<2,>=1.8.14->tfx[kfp]==1.15.0) (0.1.2)\n",
      "Collecting asn1crypto>=1.5.1 (from scramp>=1.4.5->pg8000>=1.31.1->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0)\n",
      "  Downloading asn1crypto-1.5.1-py2.py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.7.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (6.6.4)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.3.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp->cloud-sql-python-connector<2.0.0,>=1.18.2->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.20.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /opt/conda/lib/python3.10/site-packages (from beautifulsoup4->nbconvert>=5->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.8)\n",
      "Requirement already satisfied: debugpy>=1.6.5 in /opt/conda/lib/python3.10/site-packages (from ipykernel->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.8.16)\n",
      "Requirement already satisfied: arrow>=0.15.0 in /opt/conda/lib/python3.10/site-packages (from isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (1.3.0)\n",
      "Requirement already satisfied: types-python-dateutil>=2.8.10 in /opt/conda/lib/python3.10/site-packages (from arrow>=0.15.0->isoduration->jsonschema[format-nongpl]>=4.18.0->jupyter-events>=0.11.0->jupyter-server<3,>=1.8->notebook-shim>=0.2.3->nbclassic>=0.4.7->notebook>=4.4.1->widgetsnbextension~=3.6.10->ipywidgets<8,>=7->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (2.9.0.20250822)\n",
      "Requirement already satisfied: keyring in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (25.6.0)\n",
      "Requirement already satisfied: pluggy in /opt/conda/lib/python3.10/site-packages (from keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.6.0)\n",
      "Requirement already satisfied: SecretStorage>=3.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.4.0)\n",
      "Requirement already satisfied: jeepney>=0.4.2 in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (0.9.0)\n",
      "Requirement already satisfied: jaraco.classes in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (3.4.0)\n",
      "Requirement already satisfied: jaraco.functools in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (4.3.0)\n",
      "Requirement already satisfied: jaraco.context in /opt/conda/lib/python3.10/site-packages (from keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (6.0.1)\n",
      "Requirement already satisfied: more-itertools in /opt/conda/lib/python3.10/site-packages (from jaraco.classes->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (10.8.0)\n",
      "Requirement already satisfied: backports.tarfile in /opt/conda/lib/python3.10/site-packages (from jaraco.context->keyring->keyrings.google-artifactregistry-auth->apache-beam[gcp]<3,>=2.47->tfx==1.15.0->tfx[kfp]==1.15.0) (1.2.0)\n",
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.10/site-packages (from nltk->rouge-score<2,>=0.1.2->tensorflow-model-analysis<0.47.0,>=0.46.0->tfx==1.15.0->tfx[kfp]==1.15.0) (4.67.1)\n",
      "Downloading tfx-1.15.0-py3-none-any.whl (2.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_pipelines_sdk-1.15.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m64.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading absl_py-1.4.0-py3-none-any.whl (126 kB)\n",
      "Downloading apache_beam-2.68.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.6/16.6 MB\u001b[0m \u001b[31m50.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading attrs-23.2.0-py3-none-any.whl (60 kB)\n",
      "Downloading beartype-0.21.0-py3-none-any.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m49.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloud_sql_python_connector-1.18.4-py3-none-any.whl (49 kB)\n",
      "Downloading docker-4.4.4-py2.py3-none-any.whl (147 kB)\n",
      "Downloading fastavro-1.12.0-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (3.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading fasteners-0.20-py3-none-any.whl (18 kB)\n",
      "Downloading google_api_python_client-1.12.11-py2.py3-none-any.whl (62 kB)\n",
      "Downloading google_cloud_aiplatform-1.91.0-py2.py3-none-any.whl (7.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.6/7.6 MB\u001b[0m \u001b[31m55.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading kfp_pipeline_spec-0.1.16-py3-none-any.whl (19 kB)\n",
      "Downloading pydantic-1.10.24-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m101.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
      "Downloading Deprecated-1.2.18-py2.py3-none-any.whl (10.0 kB)\n",
      "Downloading fire-0.7.1-py3-none-any.whl (115 kB)\n",
      "Downloading google_cloud_bigtable-2.32.0-py3-none-any.whl (520 kB)\n",
      "Downloading google_cloud_dlp-3.32.0-py3-none-any.whl (216 kB)\n",
      "Downloading google_cloud_pubsub-2.31.1-py3-none-any.whl (319 kB)\n",
      "Downloading google_cloud_pubsublite-1.12.0-py2.py3-none-any.whl (322 kB)\n",
      "Downloading google_cloud_recommendations_ai-0.10.18-py3-none-any.whl (212 kB)\n",
      "Downloading google_cloud_spanner-3.58.0-py3-none-any.whl (501 kB)\n",
      "Downloading google_cloud_videointelligence-2.16.2-py3-none-any.whl (275 kB)\n",
      "Downloading google_cloud_vision-3.10.2-py3-none-any.whl (527 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m527.9/527.9 kB\u001b[0m \u001b[31m23.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio-1.65.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.7/5.7 MB\u001b[0m \u001b[31m70.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpcio_status-1.49.0rc1-py3-none-any.whl (14 kB)\n",
      "Downloading httplib2-0.22.0-py3-none-any.whl (96 kB)\n",
      "Downloading jsonpickle-3.4.2-py3-none-any.whl (46 kB)\n",
      "Downloading keras_tuner-1.4.7-py3-none-any.whl (129 kB)\n",
      "Downloading kubernetes-12.0.1-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ml_metadata-1.15.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.5/7.5 MB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading objsize-0.7.1-py3-none-any.whl (11 kB)\n",
      "Downloading orjson-3.11.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (132 kB)\n",
      "Downloading portpicker-1.6.0-py3-none-any.whl (16 kB)\n",
      "Downloading protobuf-3.20.3-cp310-cp310-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (1.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m50.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow-10.0.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (35.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m35.9/35.9 MB\u001b[0m \u001b[31m52.1 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading pyarrow_hotfix-0.7-py3-none-any.whl (7.9 kB)\n",
      "Downloading pydot-1.4.2-py2.py3-none-any.whl (21 kB)\n",
      "Downloading pymongo-4.15.2-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m48.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading dnspython-2.8.0-py3-none-any.whl (331 kB)\n",
      "Downloading redis-5.3.1-py3-none-any.whl (272 kB)\n",
      "Downloading requests_toolbelt-0.10.1-py2.py3-none-any.whl (54 kB)\n",
      "Downloading scipy-1.12.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (38.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.4/38.4 MB\u001b[0m \u001b[31m73.4 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading strip_hints-0.1.13-py3-none-any.whl (23 kB)\n",
      "Downloading tensorflow_data_validation-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (19.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19.0/19.0 MB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading pandas-1.5.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.1/12.1 MB\u001b[0m \u001b[31m74.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tensorflow_hub-0.15.0-py2.py3-none-any.whl (85 kB)\n",
      "Downloading tensorflow_metadata-1.15.0-py3-none-any.whl (28 kB)\n",
      "Downloading tensorflow_model_analysis-0.46.0-py3-none-any.whl (1.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipython-7.34.0-py3-none-any.whl (793 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m793.8/793.8 kB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading ipywidgets-7.8.5-py2.py3-none-any.whl (124 kB)\n",
      "Downloading jupyterlab_widgets-1.1.11-py3-none-any.whl (246 kB)\n",
      "Downloading sacrebleu-2.5.1-py3-none-any.whl (104 kB)\n",
      "Downloading tensorflow_serving_api-2.15.1-py2.py3-none-any.whl (26 kB)\n",
      "Downloading tensorflow_transform-1.15.0-py3-none-any.whl (451 kB)\n",
      "Downloading tfx_bsl-1.15.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (22.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.5/22.5 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m6m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading typer-0.19.2-py3-none-any.whl (46 kB)\n",
      "Downloading uritemplate-3.0.1-py2.py3-none-any.whl (15 kB)\n",
      "Downloading urllib3-1.26.20-py2.py3-none-any.whl (144 kB)\n",
      "Downloading widgetsnbextension-3.6.10-py2.py3-none-any.whl (1.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading grpc_interceptor-0.15.4-py3-none-any.whl (20 kB)\n",
      "Downloading pg8000-1.31.5-py3-none-any.whl (57 kB)\n",
      "Downloading PyJWT-2.10.1-py3-none-any.whl (22 kB)\n",
      "Downloading pymysql-1.1.2-py3-none-any.whl (45 kB)\n",
      "Downloading python_tds-1.17.1-py3-none-any.whl (86 kB)\n",
      "Downloading regex-2025.9.18-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.manylinux_2_28_x86_64.whl (789 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m789.9/789.9 kB\u001b[0m \u001b[31m39.7 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scramp-1.4.6-py3-none-any.whl (12 kB)\n",
      "Downloading asn1crypto-1.5.1-py2.py3-none-any.whl (105 kB)\n",
      "Downloading shellingham-1.5.4-py2.py3-none-any.whl (9.8 kB)\n",
      "Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
      "Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
      "Downloading kt_legacy-1.0.5-py3-none-any.whl (9.6 kB)\n",
      "Downloading lxml-6.0.2-cp310-cp310-manylinux_2_26_x86_64.manylinux_2_28_x86_64.whl (5.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.3/5.3 MB\u001b[0m \u001b[31m59.2 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading nltk-3.9.2-py3-none-any.whl (1.5 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.5/1.5 MB\u001b[0m \u001b[31m53.9 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
      "Downloading portalocker-3.2.0-py3-none-any.whl (22 kB)\n",
      "Building wheels for collected packages: crcmod, dill, google-apitools, kfp, hdfs, kfp-server-api, pyfarmhash, rouge-score, docopt\n",
      "\u001b[33m  DEPRECATION: Building 'crcmod' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'crcmod'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for crcmod (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for crcmod: filename=crcmod-1.7-cp310-cp310-linux_x86_64.whl size=23168 sha256=b1dfac18b4c5167810bbae8e3907a521f1fced84953331e7f620b71e648b48b4\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/85/4c/07/72215c529bd59d67e3dac29711d7aba1b692f543c808ba9e86\n",
      "\u001b[33m  DEPRECATION: Building 'dill' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'dill'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for dill (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dill: filename=dill-0.3.1.1-py3-none-any.whl size=78635 sha256=c8464397be5fbd3e92cc235556660a5e0e2deaefda189ff1b6aa700ad6cdb795\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/ea/e2/86/64980d90e297e7bf2ce588c2b96e818f5399c515c4bb8a7e4f\n",
      "\u001b[33m  DEPRECATION: Building 'google-apitools' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'google-apitools'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for google-apitools (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for google-apitools: filename=google_apitools-0.5.31-py3-none-any.whl size=131077 sha256=4a102eabd7061389fca3421babdd40d647bc3b26d7697ae31a67fc03f4c20666\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/04/b7/e0/9712f8c23a5da3d9d16fb88216b897bf60e85b12f5470f26ee\n",
      "\u001b[33m  DEPRECATION: Building 'kfp' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'kfp'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for kfp (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp: filename=kfp-1.8.22-py3-none-any.whl size=427023 sha256=0d83ba5935a6d4c838bdbbd819dd7f184614821c847662319bbae00d8d58d993\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/74/c0/fc/bf0ab209fd6ae814d7efbc821076e948c3e4884f846583ab58\n",
      "\u001b[33m  DEPRECATION: Building 'hdfs' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'hdfs'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for hdfs (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for hdfs: filename=hdfs-2.7.3-py3-none-any.whl size=34431 sha256=3185396516e74d4c8375737bcfbf8b662e814376f9e851d383ee319620c1dea6\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e5/8d/b6/99c1c0a3ac5788c866b0ecd3f48b0134a5910e6ed26011800b\n",
      "\u001b[33m  DEPRECATION: Building 'kfp-server-api' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'kfp-server-api'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for kfp-server-api (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for kfp-server-api: filename=kfp_server_api-1.8.5-py3-none-any.whl size=99777 sha256=2a6864e64c5daf9ce8b2c07cb1be7329873db581cddc68969faff65c9840d10e\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/c5/97/d5/e8a0f596dc85f5cfe383c800fbf3e29a99853bb54e01f26fca\n",
      "\u001b[33m  DEPRECATION: Building 'pyfarmhash' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'pyfarmhash'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for pyfarmhash (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for pyfarmhash: filename=pyfarmhash-0.3.2-cp310-cp310-linux_x86_64.whl size=13938 sha256=9933e1e970e3cc08a0581e2a731712d9398a36c2a02e74a2ee2894df594e943c\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/e0/08/da/f66b1f3258fe3f1e767b2136c5444dbfa9fa3f7944cc5e1983\n",
      "\u001b[33m  DEPRECATION: Building 'rouge-score' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'rouge-score'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for rouge-score (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for rouge-score: filename=rouge_score-0.1.2-py3-none-any.whl size=24987 sha256=c92b849f0e28736ae9b000318189c8c504ad57128d092be60d084554fb733ac8\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/5f/dd/89/461065a73be61a532ff8599a28e9beef17985c9e9c31e541b4\n",
      "\u001b[33m  DEPRECATION: Building 'docopt' using the legacy setup.py bdist_wheel mechanism, which will be removed in a future version. pip 25.3 will enforce this behaviour change. A possible replacement is to use the standardized build interface by setting the `--use-pep517` option, (possibly combined with `--no-build-isolation`), or adding a `pyproject.toml` file to the source tree of 'docopt'. Discussion can be found at https://github.com/pypa/pip/issues/6334\u001b[0m\u001b[33m\n",
      "\u001b[0m  Building wheel for docopt (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for docopt: filename=docopt-0.6.2-py2.py3-none-any.whl size=13783 sha256=a2f71d573e3d8cd14d8ab95e55d14900acce650cdebf8d576be2d147347d1d04\n",
      "  Stored in directory: /home/jupyter/.cache/pip/wheels/fc/ab/d4/5da2067ac95b36618c629a5f93f809425700506f72c9732fac\n",
      "Successfully built crcmod dill google-apitools kfp hdfs kfp-server-api pyfarmhash rouge-score docopt\n",
      "Installing collected packages: sortedcontainers, python-tds, pyfarmhash, pickleshare, kt-legacy, docopt, crcmod, backcall, asn1crypto, urllib3, uritemplate, strip-hints, shellingham, scramp, scipy, regex, PyMySQL, PyJWT, pydot, pydantic, pyarrow-hotfix, pyarrow, protobuf, portpicker, portalocker, orjson, objsize, lxml, jupyterlab-widgets, jsonpickle, httplib2, grpcio, fire, fasteners, fastavro, dnspython, dill, Deprecated, cloudpickle, beartype, attrs, absl-py, tensorflow-metadata, tensorflow-hub, sacrebleu, redis, pymongo, pg8000, pandas, nltk, ml-metadata, kfp-server-api, kfp-pipeline-spec, ipython, grpc-interceptor, typer, rouge-score, requests-toolbelt, keras-tuner, hdfs, grpcio-status, google-apitools, docker, kubernetes, google-api-python-client, cloud-sql-python-connector, ml-pipelines-sdk, google-cloud-vision, google-cloud-videointelligence, google-cloud-spanner, google-cloud-recommendations-ai, google-cloud-pubsub, google-cloud-dlp, google-cloud-bigtable, apache-beam, kfp, google-cloud-pubsublite, google-cloud-aiplatform, tensorflow-serving-api, tfx-bsl, tensorflow-transform, tensorflow-data-validation, widgetsnbextension, ipywidgets, tensorflow-model-analysis, tfx\n",
      "\u001b[2K  Attempting uninstall: urllib3━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [asn1crypto]]\n",
      "\u001b[2K    Found existing installation: urllib3 2.5.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [asn1crypto]\n",
      "\u001b[2K    Uninstalling urllib3-2.5.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [asn1crypto]\n",
      "\u001b[2K      Successfully uninstalled urllib3-2.5.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 8/86\u001b[0m [asn1crypto]\n",
      "\u001b[2K  Attempting uninstall: uritemplate━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [urllib3]\n",
      "\u001b[2K    Found existing installation: uritemplate 4.2.0━━━━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [urllib3]\n",
      "\u001b[2K    Uninstalling uritemplate-4.2.0:━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [urllib3]\n",
      "\u001b[2K      Successfully uninstalled uritemplate-4.2.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m 9/86\u001b[0m [urllib3]\n",
      "\u001b[2K  Attempting uninstall: scipy0m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/86\u001b[0m [uritemplate]\n",
      "\u001b[2K    Found existing installation: scipy 1.15.3━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10/86\u001b[0m [uritemplate]\n",
      "\u001b[2K    Uninstalling scipy-1.15.3:90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/86\u001b[0m [scipy]e]\n",
      "\u001b[2K      Successfully uninstalled scipy-1.15.3━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14/86\u001b[0m [scipy]\n",
      "\u001b[2K  Attempting uninstall: pydanticm━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/86\u001b[0m [regex]\n",
      "\u001b[2K    Found existing installation: pydantic 2.11.9━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/86\u001b[0m [regex]\n",
      "\u001b[2K    Uninstalling pydantic-2.11.9:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/86\u001b[0m [regex]\n",
      "\u001b[2K      Successfully uninstalled pydantic-2.11.9━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15/86\u001b[0m [regex]\n",
      "\u001b[2K  Attempting uninstall: pyarrow[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pydantic]\n",
      "\u001b[2K    Found existing installation: pyarrow 21.0.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m19/86\u001b[0m [pydantic]\n",
      "\u001b[2K    Uninstalling pyarrow-21.0.0:[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/86\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled pyarrow-21.0.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/86\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: protobuf[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/86\u001b[0m [pyarrow]\n",
      "\u001b[2K    Found existing installation: protobuf 4.25.8━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/86\u001b[0m [pyarrow]\n",
      "\u001b[2K    Uninstalling protobuf-4.25.8:━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/86\u001b[0m [pyarrow]\n",
      "\u001b[2K      Successfully uninstalled protobuf-4.25.8━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21/86\u001b[0m [pyarrow]\n",
      "\u001b[2K  Attempting uninstall: jupyterlab-widgets━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/86\u001b[0m [lxml]ze]]\n",
      "\u001b[2K    Found existing installation: jupyterlab_widgets 3.0.15━━━━\u001b[0m \u001b[32m27/86\u001b[0m [lxml]\n",
      "\u001b[2K    Uninstalling jupyterlab_widgets-3.0.15:━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27/86\u001b[0m [lxml]\n",
      "\u001b[2K      Successfully uninstalled jupyterlab_widgets-3.0.15━━━━━━\u001b[0m \u001b[32m27/86\u001b[0m [lxml]\n",
      "\u001b[2K  Attempting uninstall: httplib2[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/86\u001b[0m [jsonpickle]widgets]\n",
      "\u001b[2K    Found existing installation: httplib2 0.31.0━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/86\u001b[0m [jsonpickle]\n",
      "\u001b[2K    Uninstalling httplib2-0.31.0:90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/86\u001b[0m [jsonpickle]\n",
      "\u001b[2K      Successfully uninstalled httplib2-0.31.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m29/86\u001b[0m [jsonpickle]\n",
      "\u001b[2K  Attempting uninstall: grpcio╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/86\u001b[0m [httplib2]\n",
      "\u001b[2K    Found existing installation: grpcio 1.75.0━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/86\u001b[0m [httplib2]\n",
      "\u001b[2K    Uninstalling grpcio-1.75.0:\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/86\u001b[0m [httplib2]\n",
      "\u001b[2K      Successfully uninstalled grpcio-1.75.0━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m30/86\u001b[0m [httplib2]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31/86\u001b[0m [grpcio]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rpc'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: cloudpickle[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/86\u001b[0m [dill]thon]\n",
      "\u001b[2K    Found existing installation: cloudpickle 3.1.1━━━━━━━━━━━━\u001b[0m \u001b[32m36/86\u001b[0m [dill]\n",
      "\u001b[2K    Uninstalling cloudpickle-3.1.1:[90m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/86\u001b[0m [dill]\n",
      "\u001b[2K      Successfully uninstalled cloudpickle-3.1.1━━━━━━━━━━━━━━\u001b[0m \u001b[32m36/86\u001b[0m [dill]\n",
      "\u001b[2K  Attempting uninstall: attrsm\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K    Found existing installation: attrs 25.3.0━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K    Uninstalling attrs-25.3.0:m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K      Successfully uninstalled attrs-25.3.0━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K  Attempting uninstall: absl-py╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K    Found existing installation: absl-py 2.3.1━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K    Uninstalling absl-py-2.3.1:╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K      Successfully uninstalled absl-py-2.3.1━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39/86\u001b[0m [beartype]\n",
      "\u001b[2K  Attempting uninstall: pandas[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/86\u001b[0m [pymongo]u]\n",
      "\u001b[2K    Found existing installation: pandas 2.3.2━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46/86\u001b[0m [pymongo]\n",
      "\u001b[2K    Uninstalling pandas-2.3.2:\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/86\u001b[0m [pandas]\n",
      "\u001b[2K      Successfully uninstalled pandas-2.3.20m━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48/86\u001b[0m [pandas]\n",
      "\u001b[2K  Attempting uninstall: kfp-server-api0m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50/86\u001b[0m [ml-metadata]\n",
      "\u001b[2K    Found existing installation: kfp-server-api 2.14.3━━━━━━━━\u001b[0m \u001b[32m50/86\u001b[0m [ml-metadata]\n",
      "\u001b[2K    Uninstalling kfp-server-api-2.14.3:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K      Successfully uninstalled kfp-server-api-2.14.3━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K  Attempting uninstall: kfp-pipeline-spec\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K    Found existing installation: kfp-pipeline-spec 2.14.0━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K    Uninstalling kfp-pipeline-spec-2.14.0:[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K      Successfully uninstalled kfp-pipeline-spec-2.14.0━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K  Attempting uninstall: ipython\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K    Found existing installation: ipython 8.37.0━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K    Uninstalling ipython-8.37.0:[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K      Successfully uninstalled ipython-8.37.0m━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51/86\u001b[0m [kfp-server-api]\n",
      "\u001b[2K  Attempting uninstall: requests-toolbeltm╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m55/86\u001b[0m [typer]n]pi]\n",
      "\u001b[2K    Found existing installation: requests-toolbelt 1.0.0━━━━━━\u001b[0m \u001b[32m55/86\u001b[0m [typer]\n",
      "\u001b[2K    Uninstalling requests-toolbelt-1.0.0:0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m55/86\u001b[0m [typer]\n",
      "\u001b[2K      Successfully uninstalled requests-toolbelt-1.0.0━━━━━━━━\u001b[0m \u001b[32m55/86\u001b[0m [typer]\n",
      "\u001b[2K  Attempting uninstall: grpcio-statusm\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m58/86\u001b[0m [keras-tuner]lbelt]\n",
      "\u001b[2K    Found existing installation: grpcio-status 1.75.0━━━━━━━━━\u001b[0m \u001b[32m58/86\u001b[0m [keras-tuner]\n",
      "\u001b[2K    Uninstalling grpcio-status-1.75.0:m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━\u001b[0m \u001b[32m58/86\u001b[0m [keras-tuner]\n",
      "\u001b[2K      Successfully uninstalled grpcio-status-1.75.0━━━━━━━━━━━\u001b[0m \u001b[32m58/86\u001b[0m [keras-tuner]\n",
      "\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m60/86\u001b[0m [grpcio-status]\u001b[33m  WARNING: Failed to remove contents in a temporary directory '/opt/conda/lib/python3.10/site-packages/~rpc_status'.\n",
      "  You can safely remove it manually.\u001b[0m\u001b[33m\n",
      "\u001b[2K  Attempting uninstall: docker━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61/86\u001b[0m [google-apitools]\n",
      "\u001b[2K    Found existing installation: docker 7.1.0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61/86\u001b[0m [google-apitools]\n",
      "\u001b[2K    Uninstalling docker-7.1.0:━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61/86\u001b[0m [google-apitools]\n",
      "\u001b[2K      Successfully uninstalled docker-7.1.0[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m61/86\u001b[0m [google-apitools]\n",
      "\u001b[2K  Attempting uninstall: kubernetes━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m62/86\u001b[0m [docker]ools]\n",
      "\u001b[2K    Found existing installation: kubernetes 30.1.0m━━━━━━━━━━━\u001b[0m \u001b[32m62/86\u001b[0m [docker]\n",
      "\u001b[2K    Uninstalling kubernetes-30.1.0:m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m62/86\u001b[0m [docker]\n",
      "\u001b[2K      Successfully uninstalled kubernetes-30.1.090m━━━━━━━━━━━\u001b[0m \u001b[32m62/86\u001b[0m [docker]\n",
      "\u001b[2K  Attempting uninstall: google-api-python-client[0m\u001b[90m━━━━━━━━━━\u001b[0m \u001b[32m63/86\u001b[0m [kubernetes]\n",
      "\u001b[2K    Found existing installation: google-api-python-client 2.181.0m \u001b[32m63/86\u001b[0m [kubernetes]\n",
      "\u001b[2K    Uninstalling google-api-python-client-2.181.0:0m━━━━━━━━━━\u001b[0m \u001b[32m63/86\u001b[0m [kubernetes]\n",
      "\u001b[2K      Successfully uninstalled google-api-python-client-2.181.0[0m \u001b[32m63/86\u001b[0m [kubernetes]\n",
      "\u001b[2K  Attempting uninstall: kfp━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m74/86\u001b[0m [apache-beam]-bigtable]ons-ai]\n",
      "\u001b[2K    Found existing installation: kfp 2.14.3[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m74/86\u001b[0m [apache-beam]\n",
      "\u001b[2K    Uninstalling kfp-2.14.3:━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m74/86\u001b[0m [apache-beam]\n",
      "\u001b[2K      Successfully uninstalled kfp-2.14.3m\u001b[90m╺\u001b[0m\u001b[90m━━━━━\u001b[0m \u001b[32m74/86\u001b[0m [apache-beam]\n",
      "\u001b[2K  Attempting uninstall: google-cloud-aiplatform\u001b[90m╺\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m76/86\u001b[0m [google-cloud-pubsublite]\n",
      "\u001b[2K    Found existing installation: google-cloud-aiplatform 1.113.00m \u001b[32m76/86\u001b[0m [google-cloud-pubsublite]\n",
      "\u001b[2K    Uninstalling google-cloud-aiplatform-1.113.0:91m╸\u001b[0m\u001b[90m━━━━\u001b[0m \u001b[32m77/86\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K      Successfully uninstalled google-cloud-aiplatform-1.113.0━━━━\u001b[0m \u001b[32m77/86\u001b[0m [google-cloud-aiplatform]\n",
      "\u001b[2K  Attempting uninstall: widgetsnbextension━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m81/86\u001b[0m [tensorflow-data-validation]\n",
      "\u001b[2K    Found existing installation: widgetsnbextension 4.0.140m━━\u001b[0m \u001b[32m81/86\u001b[0m [tensorflow-data-validation]\n",
      "\u001b[2K    Uninstalling widgetsnbextension-4.0.14:0m\u001b[91m╸\u001b[0m\u001b[90m━━\u001b[0m \u001b[32m81/86\u001b[0m [tensorflow-data-validation]\n",
      "\u001b[2K      Successfully uninstalled widgetsnbextension-4.0.14[90m━━\u001b[0m \u001b[32m81/86\u001b[0m [tensorflow-data-validation]\n",
      "\u001b[2K  Attempting uninstall: ipywidgets━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m82/86\u001b[0m [widgetsnbextension]ion]\n",
      "\u001b[2K    Found existing installation: ipywidgets 8.1.70m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m82/86\u001b[0m [widgetsnbextension]\n",
      "\u001b[2K    Uninstalling ipywidgets-8.1.7:━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m82/86\u001b[0m [widgetsnbextension]\n",
      "\u001b[2K      Successfully uninstalled ipywidgets-8.1.7[90m╺\u001b[0m\u001b[90m━\u001b[0m \u001b[32m82/86\u001b[0m [widgetsnbextension]\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86/86\u001b[0m [tfx][0m [tfx]orflow-model-analysis]\n",
      "\u001b[1A\u001b[2K\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "bigframes 2.20.0 requires pyarrow>=15.0.2, but you have pyarrow 10.0.1 which is incompatible.\n",
      "db-dtypes 1.4.3 requires pyarrow>=13.0.0, but you have pyarrow 10.0.1 which is incompatible.\n",
      "geopandas 1.1.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "google-genai 1.37.0 requires pydantic<3.0.0,>=2.0.0, but you have pydantic 1.10.24 which is incompatible.\n",
      "opentelemetry-proto 1.37.0 requires protobuf<7.0,>=5.0, but you have protobuf 3.20.3 which is incompatible.\n",
      "visions 0.8.1 requires pandas>=2.0.0, but you have pandas 1.5.3 which is incompatible.\n",
      "ydata-profiling 4.16.1 requires pydantic>=2, but you have pydantic 1.10.24 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed Deprecated-1.2.18 PyJWT-2.10.1 PyMySQL-1.1.2 absl-py-1.4.0 apache-beam-2.68.0 asn1crypto-1.5.1 attrs-23.2.0 backcall-0.2.0 beartype-0.21.0 cloud-sql-python-connector-1.18.4 cloudpickle-2.2.1 crcmod-1.7 dill-0.3.1.1 dnspython-2.8.0 docker-4.4.4 docopt-0.6.2 fastavro-1.12.0 fasteners-0.20 fire-0.7.1 google-api-python-client-1.12.11 google-apitools-0.5.31 google-cloud-aiplatform-1.91.0 google-cloud-bigtable-2.32.0 google-cloud-dlp-3.32.0 google-cloud-pubsub-2.31.1 google-cloud-pubsublite-1.12.0 google-cloud-recommendations-ai-0.10.18 google-cloud-spanner-3.58.0 google-cloud-videointelligence-2.16.2 google-cloud-vision-3.10.2 grpc-interceptor-0.15.4 grpcio-1.65.5 grpcio-status-1.49.0rc1 hdfs-2.7.3 httplib2-0.22.0 ipython-7.34.0 ipywidgets-7.8.5 jsonpickle-3.4.2 jupyterlab-widgets-1.1.11 keras-tuner-1.4.7 kfp-1.8.22 kfp-pipeline-spec-0.1.16 kfp-server-api-1.8.5 kt-legacy-1.0.5 kubernetes-12.0.1 lxml-6.0.2 ml-metadata-1.15.0 ml-pipelines-sdk-1.15.0 nltk-3.9.2 objsize-0.7.1 orjson-3.11.3 pandas-1.5.3 pg8000-1.31.5 pickleshare-0.7.5 portalocker-3.2.0 portpicker-1.6.0 protobuf-3.20.3 pyarrow-10.0.1 pyarrow-hotfix-0.7 pydantic-1.10.24 pydot-1.4.2 pyfarmhash-0.3.2 pymongo-4.15.2 python-tds-1.17.1 redis-5.3.1 regex-2025.9.18 requests-toolbelt-0.10.1 rouge-score-0.1.2 sacrebleu-2.5.1 scipy-1.12.0 scramp-1.4.6 shellingham-1.5.4 sortedcontainers-2.4.0 strip-hints-0.1.13 tensorflow-data-validation-1.15.1 tensorflow-hub-0.15.0 tensorflow-metadata-1.15.0 tensorflow-model-analysis-0.46.0 tensorflow-serving-api-2.15.1 tensorflow-transform-1.15.0 tfx-1.15.0 tfx-bsl-1.15.1 typer-0.19.2 uritemplate-3.0.1 urllib3-1.26.20 widgetsnbextension-3.6.10\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install --upgrade pip \n",
    "%pip uninstall tensorflow tensorflow-tensorboard tensorflow-io tensorflow-cloud -y \n",
    "%pip install tensorflow==2.15.1\n",
    "%pip uninstall tfx -y \n",
    "%pip install -U \"tfx[kfp]==1.15.0\"\n",
    "\n",
    "# You may see package dependency errors in the output below. You may ignore these to run the cells of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EwT0nov5QO1M"
   },
   "source": [
    "#### Restart the runtime\n",
    "\n",
    "Restart the runtime to ensure the following cells use the updated versions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-CRyIL4LVDlQ"
   },
   "source": [
    "You can restart the runtime with following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "KHTSzMygoBF6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "import sys\n",
    "if not 'google.colab' in sys.modules:\n",
    "  # Automatically restart kernel after installs\n",
    "  import IPython\n",
    "  app = IPython.Application.instance()\n",
    "  app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3_SveIKxaENu"
   },
   "source": [
    "Check the package versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "Xd-iP9wEaENu",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-02 01:30:36.581722: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-02 01:30:37.342469: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2025-10-02 01:30:37.342704: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2025-10-02 01:30:37.539668: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-10-02 01:30:37.913392: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2025-10-02 01:30:37.914347: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.15.1\n",
      "TFX version: 1.15.0\n",
      "KFP version: 1.8.22\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print('TensorFlow version: {}'.format(tf.__version__))\n",
    "from tfx import v1 as tfx\n",
    "print('TFX version: {}'.format(tfx.__version__))\n",
    "import kfp\n",
    "print('KFP version: {}'.format(kfp.__version__))\n",
    "\n",
    "# You may see a WARNING issued. You can safely ignore this until the TFX and KFP versions are displayed in the cell output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aDtLdSkvqPHe"
   },
   "source": [
    "### Set up variables\n",
    "\n",
    "We will set up some variables used to customize the pipelines below. Following\n",
    "information is required:\n",
    "\n",
    "* GCP Project id. You can find your Project ID in the panel with your lab instructions.\n",
    "* GCP Region to run pipelines. For more information about the regions that\n",
    "Vertex Pipelines is available in, see the\n",
    "[Vertex AI locations guide](https://cloud.google.com/vertex-ai/docs/general/locations#feature-availability).\n",
    "* Google Cloud Storage Bucket to store pipeline outputs.\n",
    "\n",
    "**Enter required values in the cell below before running it**.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "EcUseqJaE2XN",
    "tags": []
   },
   "outputs": [],
   "source": [
    "GOOGLE_CLOUD_PROJECT = ''    \n",
    "GOOGLE_CLOUD_REGION = ''     \n",
    "GCS_BUCKET_NAME = GOOGLE_CLOUD_PROJECT + '-gcs'\n",
    "\n",
    "if not (GOOGLE_CLOUD_PROJECT and GOOGLE_CLOUD_REGION and GCS_BUCKET_NAME):\n",
    "    from absl import logging\n",
    "    logging.error('Please set all required parameters.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GAaCPLjgiJrO"
   },
   "source": [
    "Set `gcloud` to use your project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "VkWdxe4TXRHk",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "!gcloud config set project {GOOGLE_CLOUD_PROJECT}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "CPN6UL5CazNy",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PIPELINE_ROOT: gs://qwiklabs-gcp-02-e562111faf22-gcs/pipeline_root/penguin-vertex-pipelines\n",
      "MODULE_ROOT: gs://qwiklabs-gcp-02-e562111faf22-gcs/pipeline_module/penguin-vertex-pipelines\n",
      "DATA_ROOT: gs://qwiklabs-gcp-02-e562111faf22-gcs/data/penguin-vertex-pipelines\n",
      "SERVING_MODEL_DIR: gs://qwiklabs-gcp-02-e562111faf22-gcs/serving_model/penguin-vertex-pipelines\n"
     ]
    }
   ],
   "source": [
    "PIPELINE_NAME = 'penguin-vertex-pipelines'\n",
    "\n",
    "# Path to various pipeline artifact.\n",
    "PIPELINE_ROOT = 'gs://{}/pipeline_root/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for users' Python module.\n",
    "MODULE_ROOT = 'gs://{}/pipeline_module/{}'.format(\n",
    "    GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# Paths for input data.\n",
    "DATA_ROOT = 'gs://{}/data/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "# This is the path where your model will be pushed for serving.\n",
    "SERVING_MODEL_DIR = 'gs://{}/serving_model/{}'.format(GCS_BUCKET_NAME, PIPELINE_NAME)\n",
    "\n",
    "print('PIPELINE_ROOT: {}'.format(PIPELINE_ROOT))\n",
    "print('MODULE_ROOT: {}'.format(MODULE_ROOT))\n",
    "print('DATA_ROOT: {}'.format(DATA_ROOT))\n",
    "print('SERVING_MODEL_DIR: {}'.format(SERVING_MODEL_DIR))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8F2SRwRLSYGa"
   },
   "source": [
    "### Prepare example data\n",
    "The dataset we are using is the\n",
    "[Palmer Penguins dataset](https://allisonhorst.github.io/palmerpenguins/articles/intro.html).\n",
    "\n",
    "There are four numeric features in this dataset:\n",
    "\n",
    "* culmen_length_mm\n",
    "* culmen_depth_mm\n",
    "* flipper_length_mm\n",
    "* body_mass_g\n",
    "\n",
    "All features were already normalized\n",
    "to have range [0,1]. We will build a classification model which predicts the\n",
    "`species` of penguins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "11J7XiCq6AFP"
   },
   "source": [
    "We need to make our own copy of the dataset. Because TFX ExampleGen reads\n",
    "inputs from a directory, we need to create a directory and copy dataset to it\n",
    "on GCS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "4fxMs6u86acP",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv [Content-Type=application/octet-stream]...\n",
      "/ [1 files][ 25.0 KiB/ 25.0 KiB]                                                \n",
      "Operation completed over 1 objects/25.0 KiB.                                     \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp gs://download.tensorflow.org/data/palmer_penguins/penguins_processed.csv {DATA_ROOT}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ASpoNmxKSQjI"
   },
   "source": [
    "Take a quick look at the CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "-eSz28UDSnlG",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species,culmen_length_mm,culmen_depth_mm,flipper_length_mm,body_mass_g\n",
      "0,0.2545454545454545,0.6666666666666666,0.15254237288135594,0.2916666666666667\n",
      "0,0.26909090909090905,0.5119047619047618,0.23728813559322035,0.3055555555555556\n",
      "0,0.29818181818181805,0.5833333333333334,0.3898305084745763,0.1527777777777778\n",
      "0,0.16727272727272732,0.7380952380952381,0.3559322033898305,0.20833333333333334\n",
      "0,0.26181818181818167,0.892857142857143,0.3050847457627119,0.2638888888888889\n",
      "0,0.24727272727272717,0.5595238095238096,0.15254237288135594,0.2569444444444444\n",
      "0,0.25818181818181823,0.773809523809524,0.3898305084745763,0.5486111111111112\n",
      "0,0.32727272727272727,0.5357142857142859,0.1694915254237288,0.1388888888888889\n",
      "0,0.23636363636363636,0.9642857142857142,0.3220338983050847,0.3055555555555556\n"
     ]
    }
   ],
   "source": [
    "!gsutil cat {DATA_ROOT}/penguins_processed.csv | head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should be able to see five values. `species` is one of 0, 1 or 2, and all other features should have values between 0 and 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nH6gizcpSwWV"
   },
   "source": [
    "## Create a pipeline\n",
    "\n",
    "TFX pipelines are defined using Python APIs. We will define a pipeline which\n",
    "consists of three components:\n",
    "\n",
    "* CsvExampleGen: Reads in data files and convert them to TFX internal format for further processing. There are multiple ExampleGens for various formats. In this tutorial, we will use CsvExampleGen which takes CSV file input.\n",
    "* Trainer: Trains an ML model. Trainer component requires a model definition code from users. You can use TensorFlow APIs to specify how to train a model and save it in a _savedmodel format.\n",
    "* Pusher: Copies the trained model outside of the TFX pipeline. Pusher component can be thought of an deployment process of the trained ML model.\n",
    "\n",
    "Our pipeline will be almost identical to a basic [TFX pipeline](https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple).\n",
    "\n",
    "The only difference is that we don't need to set `metadata_connection_config`\n",
    "which is used to locate\n",
    "[ML Metadata](https://www.tensorflow.org/tfx/guide/mlmd) database. Because\n",
    "Vertex Pipelines uses a managed metadata service, users don't need to care\n",
    "of it, and we don't need to specify the parameter.\n",
    "\n",
    "Before actually define the pipeline, we need to write a model code for the\n",
    "Trainer component first."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lOjDv93eS5xV"
   },
   "source": [
    "### Write model code.\n",
    "\n",
    "We will create a simple DNN model for classification using TensorFlow Keras API. This model training code will be saved to a separate file.\n",
    "\n",
    "In this tutorial we will use __Generic Trainer__ of TFX which support Keras-based models. You need to write a Python file containing run_fn function, which is the entrypoint for the `Trainer` component."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "aES7Hv5QTDK3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "_trainer_module_file = 'penguin_trainer.py'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Gnc67uQNTDfW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing penguin_trainer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile {_trainer_module_file}\n",
    "\n",
    "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple\n",
    "\n",
    "from typing import List\n",
    "from absl import logging\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "\n",
    "\n",
    "from tfx import v1 as tfx\n",
    "from tfx_bsl.public import tfxio\n",
    "\n",
    "from tensorflow_metadata.proto.v0 import schema_pb2\n",
    "\n",
    "_FEATURE_KEYS = [\n",
    "    'culmen_length_mm', 'culmen_depth_mm', 'flipper_length_mm', 'body_mass_g'\n",
    "]\n",
    "_LABEL_KEY = 'species'\n",
    "\n",
    "_TRAIN_BATCH_SIZE = 20\n",
    "_EVAL_BATCH_SIZE = 10\n",
    "\n",
    "# Since we're not generating or creating a schema, we will instead create\n",
    "# a feature spec.  Since there are a fairly small number of features this is\n",
    "# manageable for this dataset.\n",
    "_FEATURE_SPEC = {\n",
    "    **{\n",
    "        feature: tf.io.FixedLenFeature(shape=[1], dtype=tf.float32)\n",
    "           for feature in _FEATURE_KEYS\n",
    "       },\n",
    "    _LABEL_KEY: tf.io.FixedLenFeature(shape=[1], dtype=tf.int64)\n",
    "}\n",
    "\n",
    "\n",
    "def _input_fn(file_pattern: List[str],\n",
    "              data_accessor: tfx.components.DataAccessor,\n",
    "              schema: schema_pb2.Schema,\n",
    "              batch_size: int) -> tf.data.Dataset:\n",
    "  \"\"\"Generates features and label for training.\n",
    "\n",
    "  Args:\n",
    "    file_pattern: List of paths or patterns of input tfrecord files.\n",
    "    data_accessor: DataAccessor for converting input to RecordBatch.\n",
    "    schema: schema of the input data.\n",
    "    batch_size: representing the number of consecutive elements of returned\n",
    "      dataset to combine in a single batch\n",
    "\n",
    "  Returns:\n",
    "    A dataset that contains (features, indices) tuple where features is a\n",
    "      dictionary of Tensors, and indices is a single Tensor of label indices.\n",
    "  \"\"\"\n",
    "  return data_accessor.tf_dataset_factory(\n",
    "      file_pattern,\n",
    "      tfxio.TensorFlowDatasetOptions(\n",
    "          batch_size=batch_size, label_key=_LABEL_KEY),\n",
    "      schema=schema).repeat()\n",
    "\n",
    "\n",
    "def _make_keras_model() -> tf.keras.Model:\n",
    "  \"\"\"Creates a DNN Keras model for classifying penguin data.\n",
    "\n",
    "  Returns:\n",
    "    A Keras Model.\n",
    "  \"\"\"\n",
    "  # The model below is built with Functional API, please refer to\n",
    "  # https://www.tensorflow.org/guide/keras/overview for all API options.\n",
    "  inputs = [keras.layers.Input(shape=(1,), name=f) for f in _FEATURE_KEYS]\n",
    "  d = keras.layers.concatenate(inputs)\n",
    "  for _ in range(2):\n",
    "    d = keras.layers.Dense(8, activation='relu')(d)\n",
    "  outputs = keras.layers.Dense(3)(d)\n",
    "\n",
    "  model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "  model.compile(\n",
    "      optimizer=keras.optimizers.Adam(1e-2),\n",
    "      loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "      metrics=[keras.metrics.SparseCategoricalAccuracy()])\n",
    "\n",
    "  model.summary(print_fn=logging.info)\n",
    "  return model\n",
    "\n",
    "\n",
    "# TFX Trainer will call this function.\n",
    "def run_fn(fn_args: tfx.components.FnArgs):\n",
    "  \"\"\"Train the model based on given args.\n",
    "\n",
    "  Args:\n",
    "    fn_args: Holds args used to train the model as name/value pairs.\n",
    "  \"\"\"\n",
    "\n",
    "  # This schema is usually either an output of SchemaGen or a manually-curated\n",
    "  # version provided by pipeline author. A schema can also derived from TFT\n",
    "  # graph if a Transform component is used. In the case when either is missing,\n",
    "  # `schema_from_feature_spec` could be used to generate schema from very simple\n",
    "  # feature_spec, but the schema returned would be very primitive.\n",
    "  schema = schema_utils.schema_from_feature_spec(_FEATURE_SPEC)\n",
    "\n",
    "  train_dataset = _input_fn(\n",
    "      fn_args.train_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_TRAIN_BATCH_SIZE)\n",
    "  eval_dataset = _input_fn(\n",
    "      fn_args.eval_files,\n",
    "      fn_args.data_accessor,\n",
    "      schema,\n",
    "      batch_size=_EVAL_BATCH_SIZE)\n",
    "\n",
    "  model = _make_keras_model()\n",
    "  model.fit(\n",
    "      train_dataset,\n",
    "      steps_per_epoch=fn_args.train_steps,\n",
    "      validation_data=eval_dataset,\n",
    "      validation_steps=fn_args.eval_steps)\n",
    "\n",
    "  # The result of the training should be saved in `fn_args.serving_model_dir`\n",
    "  # directory.\n",
    "  model.save(fn_args.serving_model_dir, save_format='tf')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-LsYx8MpYvPv"
   },
   "source": [
    "Copy the module file to GCS which can be accessed from the pipeline components.\n",
    "Because model training happens on GCP, we need to upload this model definition. \n",
    "\n",
    "Otherwise, you might want to build a container image including the module file\n",
    "and use the image to run the pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "rMMs5wuNYAbc",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://penguin_trainer.py [Content-Type=text/x-python]...\n",
      "/ [1 files][  3.8 KiB/  3.8 KiB]                                                \n",
      "Operation completed over 1 objects/3.8 KiB.                                      \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp {_trainer_module_file} {MODULE_ROOT}/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3OkNz3gTLwM"
   },
   "source": [
    "### Write a pipeline definition\n",
    "\n",
    "We will define a function to create a TFX pipeline."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "M49yYVNBTPd4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Copied from https://www.tensorflow.org/tfx/tutorials/tfx/penguin_simple and\n",
    "# slightly modified because we don't need `metadata_path` argument.\n",
    "\n",
    "def _create_pipeline(pipeline_name: str, pipeline_root: str, data_root: str,\n",
    "                     module_file: str, serving_model_dir: str,\n",
    "                     ) -> tfx.dsl.Pipeline:\n",
    "  \"\"\"Creates a three component penguin pipeline with TFX.\"\"\"\n",
    "  # Brings data into the pipeline.\n",
    "  example_gen = tfx.components.CsvExampleGen(input_base=data_root)\n",
    "\n",
    "  # Uses user-provided Python function that trains a model.\n",
    "  trainer = tfx.components.Trainer(\n",
    "      module_file=module_file,\n",
    "      examples=example_gen.outputs['examples'],\n",
    "      train_args=tfx.proto.TrainArgs(num_steps=100),\n",
    "      eval_args=tfx.proto.EvalArgs(num_steps=5))\n",
    "\n",
    "  # Pushes the model to a filesystem destination.\n",
    "  pusher = tfx.components.Pusher(\n",
    "      model=trainer.outputs['model'],\n",
    "      push_destination=tfx.proto.PushDestination(\n",
    "          filesystem=tfx.proto.PushDestination.Filesystem(\n",
    "              base_directory=serving_model_dir)))\n",
    "\n",
    "  # Following three components will be included in the pipeline.\n",
    "  components = [\n",
    "      example_gen,\n",
    "      trainer,\n",
    "      pusher,\n",
    "  ]\n",
    "\n",
    "  return tfx.dsl.Pipeline(\n",
    "      pipeline_name=pipeline_name,\n",
    "      pipeline_root=pipeline_root,\n",
    "      components=components)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mJbq07THU2GV"
   },
   "source": [
    "## Run the pipeline on Vertex Pipelines.\n",
    "\n",
    "TFX provides multiple orchestrators to run your pipeline. In this tutorial we\n",
    "will use the Vertex Pipelines together with the Kubeflow V2 dag runner."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mp0AkmrPdUb"
   },
   "source": [
    "We need to define a runner to actually run the pipeline. You will compile\n",
    "your pipeline into our pipeline definition format using TFX APIs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "fAtfOZTYWJu-",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "running bdist_wheel\n",
      "running build\n",
      "running build_py\n",
      "creating build/lib\n",
      "copying penguin_trainer.py -> build/lib\n",
      "installing to /var/tmp/tmpi3oxev7t\n",
      "running install\n",
      "running install_lib\n",
      "copying build/lib/penguin_trainer.py -> /var/tmp/tmpi3oxev7t/.\n",
      "running install_egg_info\n",
      "running egg_info\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/setuptools/_distutils/cmd.py:90: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
      "!!\n",
      "\n",
      "        ********************************************************************************\n",
      "        Please avoid running ``setup.py`` directly.\n",
      "        Instead, use pypa/build, pypa/installer or other\n",
      "        standards-based tools.\n",
      "\n",
      "        By 2025-Oct-31, you need to update your project and remove deprecated calls\n",
      "        or your builds will no longer be supported.\n",
      "\n",
      "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
      "        ********************************************************************************\n",
      "\n",
      "!!\n",
      "  self.initialize_options()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "creating tfx_user_code_Trainer.egg-info\n",
      "writing tfx_user_code_Trainer.egg-info/PKG-INFO\n",
      "writing dependency_links to tfx_user_code_Trainer.egg-info/dependency_links.txt\n",
      "writing top-level names to tfx_user_code_Trainer.egg-info/top_level.txt\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "reading manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "writing manifest file 'tfx_user_code_Trainer.egg-info/SOURCES.txt'\n",
      "Copying tfx_user_code_Trainer.egg-info to /var/tmp/tmpi3oxev7t/./tfx_user_code_Trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3.10.egg-info\n",
      "running install_scripts\n",
      "creating /var/tmp/tmpi3oxev7t/tfx_user_code_trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/WHEEL\n",
      "creating '/var/tmp/tmp9ogwn47v/tfx_user_code_trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9-py3-none-any.whl' and adding '/var/tmp/tmpi3oxev7t' to it\n",
      "adding 'penguin_trainer.py'\n",
      "adding 'tfx_user_code_trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/METADATA'\n",
      "adding 'tfx_user_code_trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/WHEEL'\n",
      "adding 'tfx_user_code_trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/top_level.txt'\n",
      "adding 'tfx_user_code_trainer-0.0+afa8d5dfaf2942b08385545b5e095850331200a5d7a669b1791b3e7efcc5fdd9.dist-info/RECORD'\n",
      "removing /var/tmp/tmpi3oxev7t\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "PIPELINE_DEFINITION_FILE = PIPELINE_NAME + '_pipeline.json'\n",
    "\n",
    "runner = tfx.orchestration.experimental.KubeflowV2DagRunner(\n",
    "    config=tfx.orchestration.experimental.KubeflowV2DagRunnerConfig(),\n",
    "    output_filename=PIPELINE_DEFINITION_FILE)\n",
    "# Following function will write the pipeline definition to PIPELINE_DEFINITION_FILE.\n",
    "_ = runner.run(\n",
    "    _create_pipeline(\n",
    "        pipeline_name=PIPELINE_NAME,\n",
    "        pipeline_root=PIPELINE_ROOT,\n",
    "        data_root=DATA_ROOT,\n",
    "        module_file=os.path.join(MODULE_ROOT, _trainer_module_file),\n",
    "        serving_model_dir=SERVING_MODEL_DIR))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fWyITYSDd8w4"
   },
   "source": [
    "The generated definition file can be submitted using kfp client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "tI71jlEvWMV7"
   },
   "outputs": [],
   "source": [
    "# docs_infra: no_execute\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud.aiplatform import pipeline_jobs\n",
    "\n",
    "aiplatform.init(project=GOOGLE_CLOUD_PROJECT, location=GOOGLE_CLOUD_REGION)\n",
    "\n",
    "job = pipeline_jobs.PipelineJob(template_path=PIPELINE_DEFINITION_FILE,\n",
    "                                display_name=PIPELINE_NAME)\n",
    "job.run(sync=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L3k9f5IVQXcQ"
   },
   "source": [
    "Visit __Vertex AI > Pipelines__ in your Google Cloud Console page to see the progress.\n",
    "\n",
    "Click on your `penguin-vertex-pipelines-xxx` run:\n",
    "\n",
    "![pipeline_start](01_pipeline_start.png)\n",
    "\n",
    "Explore the information displayed in each step while you wait for the job to progress.\n",
    "\n",
    "On completion, your pipeline UI should look similar to this:\n",
    "\n",
    "![pipeline_end](02_pipeline_completed.png)\n",
    "\n",
    "This job will take about 15 minutes in total to complete. Once complete, return to the lab to check your progress."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "pknVo1kM2wI2"
   ],
   "name": "Simple TFX Pipeline for Vertex Pipelines",
   "provenance": [],
   "toc_visible": true
  },
  "environment": {
   "kernel": "conda-base-py",
   "name": "workbench-notebooks.m133",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m133"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel) (Local) (Local)",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
